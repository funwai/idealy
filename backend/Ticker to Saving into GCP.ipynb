{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dbc5cb-c9ae-4b55-b98b-99ba7f9f4794",
   "metadata": {},
   "source": [
    "## Pull all data and store into GCP using Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7165a0-414e-4d0e-a31b-ca9f679756a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CIK from TICKER\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "BASE = \"https://data.sec.gov\"\n",
    "HEADERS = {\"User-Agent\": \"kurio-agent/1.0 (potatojacket9@gmail.com)\"}\n",
    "\n",
    "## Step 1. Get CIK for the input ticker symbol~\n",
    "def get_cik(ticker):\n",
    "    \"\"\"Retrieve CIK for a given ticker symbol\"\"\"\n",
    "    res = requests.get(f\"{BASE}/submissions/CIK{ticker}.json\", headers=HEADERS)\n",
    "    if res.status_code != 200:\n",
    "        # fallback: try SEC ticker endpoint\n",
    "        lookup = requests.get(f\"https://www.sec.gov/files/company_tickers.json\", headers=HEADERS).json()\n",
    "        for _, c in lookup.items():\n",
    "            if c[\"ticker\"].lower() == ticker.lower():\n",
    "                return str(c[\"cik_str\"]).zfill(10)\n",
    "    return None\n",
    "\n",
    "## Step 2. Get latest 10K url for the CIK (ticker)\n",
    "def get_latest_10k_url(cik):\n",
    "    \"\"\"Retrieve latest 10-K filing document URL and dates for a given CIK\"\"\"\n",
    "    url = f\"{BASE}/submissions/CIK{cik}.json\"\n",
    "    res = requests.get(url, headers=HEADERS)\n",
    "    data = res.json()\n",
    "\n",
    "    for form, acc, filing_date, report_date in zip(\n",
    "        data[\"filings\"][\"recent\"][\"form\"],\n",
    "        data[\"filings\"][\"recent\"][\"accessionNumber\"],\n",
    "        data[\"filings\"][\"recent\"][\"filingDate\"],\n",
    "        data[\"filings\"][\"recent\"][\"reportDate\"]\n",
    "    ):\n",
    "        if form == \"10-K\":\n",
    "            acc_num = acc.replace(\"-\", \"\")\n",
    "            filing_url = f\"https://www.sec.gov/Archives/edgar/data/{int(cik)}/{acc_num}/{acc}-index.html\"\n",
    "            return filing_url, filing_date, report_date\n",
    "\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840f39b-cc73-49c6-a634-e2b0e4f62e9a",
   "metadata": {},
   "source": [
    "### [A] Get financial statements - income statement, cashflow statement - from 10K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6100c0-66d3-413a-b40e-eb63b9e618b2",
   "metadata": {},
   "source": [
    "#### [A1] Supporting functions for income statement, cashflow statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5212b1-0043-4b22-9713-583b858e3032",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Find actual XBRL XML file from 10K URL\n",
    "def get_primary_xbrl_url(index_url):\n",
    "    \"\"\"Find the main XBRL (XML) file inside the 10-K index page\"\"\"\n",
    "    res = requests.get(index_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        href = link[\"href\"]\n",
    "        if href.endswith(\".xml\") and not any(\n",
    "            x in href for x in [\"_cal.xml\", \"_lab.xml\", \"_pre.xml\", \"_def.xml\"]\n",
    "        ):\n",
    "            return \"https://www.sec.gov\" + href\n",
    "\n",
    "    return None\n",
    "\n",
    "## Step 4a. Define ability to find to extract cashflow tags from XML soup (input is soup). This is not dependent on any function\n",
    "def parse_cashflow_from_xbrl(soup):\n",
    "    tags = {\n",
    "        # Operating\n",
    "        \"Net profit (or loss if negative)\": \"us-gaap:NetIncomeLoss\",\n",
    "        \"Depreciation (wear & tear on assets)\": \"us-gaap:DepreciationDepletionAndAmortization\",\n",
    "        \"stock_comp\": \"us-gaap:ShareBasedCompensation\",\n",
    "        \"change_ar\": \"us-gaap:IncreaseDecreaseInAccountsReceivable\",\n",
    "        \"change_inventory\": \"us-gaap:IncreaseDecreaseInInventory\",\n",
    "        \"change_ap\": \"us-gaap:IncreaseDecreaseInAccountsPayable\",\n",
    "        \"Cash from day-to-day business (Operating Cashflow)\": \"us-gaap:NetCashProvidedByUsedInOperatingActivities\",\n",
    "\n",
    "        # Investing\n",
    "        \"Buying equipment/buildings (Capital Expenditure)\": \"us-gaap:PaymentsToAcquirePropertyPlantAndEquipment\",\n",
    "        \"acquisitions\": \"us-gaap:PaymentsToAcquireBusinessesNetOfCashAcquired\",\n",
    "        \"asset_sales\": \"us-gaap:ProceedsFromSaleOfPropertyPlantAndEquipment\",\n",
    "        \"investments_purchase\": \"us-gaap:PaymentsToAcquireMarketableSecurities\",\n",
    "        \"investments_maturity\": \"us-gaap:ProceedsFromMaturitiesOfMarketableSecurities\",\n",
    "        \"Cash from investments (Buying/Selling assets)\": \"us-gaap:NetCashProvidedByUsedInInvestingActivities\",\n",
    "\n",
    "        # Financing\n",
    "        \"Money raised from issuing new shares\": \"us-gaap:ProceedsFromIssuanceOfCommonStock\",\n",
    "        \"Money spent buying back shares of company\": \"us-gaap:PaymentsForRepurchaseOfCommonStock\",\n",
    "        \"Borrowed money (New loans or bonds)\": \"us-gaap:ProceedsFromIssuanceOfLongTermDebt\",\n",
    "        \"Loan repayments\": \"us-gaap:RepaymentsOfLongTermDebt\",\n",
    "        \"Dividends paid to shareholders\": \"us-gaap:PaymentsOfDividends\",\n",
    "        \"Cash from investors and loans (Financing activities)\": \"us-gaap:NetCashProvidedByUsedInFinancingActivities\",\n",
    "\n",
    "        # Summary\n",
    "        \"Change in cash during the period\": \"us-gaap:CashAndCashEquivalentsPeriodIncreaseDecrease\",\n",
    "        \"Cash at the beginning of the period\": \"us-gaap:CashAndCashEquivalentsAtBeginningOfPeriod\",\n",
    "        \"Cash remaining at the end of the period\": \"us-gaap:CashAndCashEquivalentsAtCarryingValue\",\n",
    "    }\n",
    "\n",
    "    data = {}\n",
    "    for key, tag in tags.items():\n",
    "        el = soup.find(tag)\n",
    "        if el and hasattr(el, \"text\"):\n",
    "            try:\n",
    "                data[key] = float(el.text.strip().replace(\",\", \"\"))\n",
    "            except ValueError:\n",
    "                data[key] = el.text.strip()\n",
    "        else:\n",
    "            data[key] = None\n",
    "\n",
    "    return data\n",
    "\n",
    "## Step 4b. Define ability to find to extract cashflow tags from XML soup (input is soup). This is not dependent on any function\n",
    "def parse_income_from_xbrl(soup):\n",
    "    \"\"\"\n",
    "    Extract key income statement values from an XBRL soup object and group\n",
    "    them into: revenue, expenses, profit, and shares.\n",
    "    If some values are missing, compute derived ones (e.g. Gross Profit = Revenue - Cost of Revenue).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define XBRL tags grouped by category\n",
    "    tags = {\n",
    "        \"revenue\": {\n",
    "            \"Total Revenue\": [\n",
    "                \"us-gaap:Revenues\",\n",
    "                \"us-gaap:RevenueFromContractWithCustomerExcludingAssessedTax\",\n",
    "                \"us-gaap:SalesRevenueNet\",\n",
    "                \"us-gaap:SalesRevenueGoodsNet\",\n",
    "                \"us-gaap:SalesRevenueServicesNet\"\n",
    "            ],\n",
    "            \"Advertising Revenue\": [\"us-gaap:AdvertisingRevenue\"],\n",
    "            \"Interest Income\": [\"us-gaap:InterestIncome\"],\n",
    "            \"Other Income\": [\"us-gaap:OtherNonoperatingIncomeExpense\"]\n",
    "        },\n",
    "\n",
    "        \"expenses\": {\n",
    "            \"Cost of Revenue\": [\"us-gaap:CostOfRevenue\", \"us-gaap:CostOfGoodsSold\"],\n",
    "            \"Research & Development\": [\"us-gaap:ResearchAndDevelopmentExpense\"],\n",
    "            \"Sales & Marketing\": [\"us-gaap:SellingAndMarketingExpense\"],\n",
    "            \"General & Administrative\": [\"us-gaap:GeneralAndAdministrativeExpense\"],\n",
    "            \"Operating Expenses (Total)\": [\"us-gaap:OperatingExpenses\"],\n",
    "            \"Interest Expense\": [\"us-gaap:InterestExpense\"],\n",
    "            \"Income Tax Expense\": [\"us-gaap:IncomeTaxExpenseBenefit\"]\n",
    "        },\n",
    "\n",
    "        \"profit\": {\n",
    "            \"Gross Profit\": [\"us-gaap:GrossProfit\"],\n",
    "            \"Operating Income\": [\"us-gaap:OperatingIncomeLoss\"],\n",
    "            \"Income Before Tax\": [\n",
    "                \"us-gaap:IncomeLossFromContinuingOperationsBeforeIncomeTaxesExtraordinaryItemsNoncontrollingInterest\"\n",
    "            ],\n",
    "            \"Net Income\": [\"us-gaap:NetIncomeLoss\"]\n",
    "        },\n",
    "\n",
    "        \"shares\": {\n",
    "            \"Earnings per Share (Basic)\": [\"us-gaap:EarningsPerShareBasic\"],\n",
    "            \"Earnings per Share (Diluted)\": [\"us-gaap:EarningsPerShareDiluted\"],\n",
    "            \"Weighted Average Shares Outstanding (Basic)\": [\n",
    "                \"us-gaap:WeightedAverageNumberOfSharesOutstandingBasic\"\n",
    "            ],\n",
    "            \"Weighted Average Shares Outstanding (Diluted)\": [\n",
    "                \"us-gaap:WeightedAverageNumberOfDilutedSharesOutstanding\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Helper function to extract numeric value from XBRL\n",
    "    def extract_value(tag_list):\n",
    "        for tag in tag_list:\n",
    "            el = soup.find(tag)\n",
    "            if el and el.text.strip():\n",
    "                try:\n",
    "                    return float(el.text.strip().replace(\",\", \"\"))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    # Parse raw values from XBRL\n",
    "    grouped_data = {}\n",
    "    for section, section_tags in tags.items():\n",
    "        grouped_data[section] = {}\n",
    "        for label, tag_list in section_tags.items():\n",
    "            grouped_data[section][label] = extract_value(tag_list)\n",
    "\n",
    "    # --- üßÆ Compute derived metrics ---\n",
    "    rev = grouped_data[\"revenue\"].get(\"Total Revenue\")\n",
    "    cost = grouped_data[\"expenses\"].get(\"Cost of Revenue\")\n",
    "    gross = grouped_data[\"profit\"].get(\"Gross Profit\")\n",
    "    op_exp = grouped_data[\"expenses\"].get(\"Operating Expenses (Total)\")\n",
    "    r_and_d = grouped_data[\"expenses\"].get(\"Research & Development\")\n",
    "    s_and_m = grouped_data[\"expenses\"].get(\"Sales & Marketing\")\n",
    "    g_and_a = grouped_data[\"expenses\"].get(\"General & Administrative\")\n",
    "    op_inc = grouped_data[\"profit\"].get(\"Operating Income\")\n",
    "\n",
    "    # Gross Profit = Revenue - Cost of Revenue\n",
    "    if gross is None and rev is not None and cost is not None:\n",
    "        grouped_data[\"profit\"][\"Gross Profit\"] = rev - cost\n",
    "\n",
    "    # Operating Expenses (Total) = R&D + Sales & Marketing + G&A\n",
    "    if op_exp is None and any(v is not None for v in [r_and_d, s_and_m, g_and_a]):\n",
    "        total = sum(v for v in [r_and_d, s_and_m, g_and_a] if v is not None)\n",
    "        grouped_data[\"expenses\"][\"Operating Expenses (Total)\"] = total\n",
    "\n",
    "    # Operating Income = Gross Profit - Operating Expenses\n",
    "    gross = grouped_data[\"profit\"].get(\"Gross Profit\")\n",
    "    op_exp = grouped_data[\"expenses\"].get(\"Operating Expenses (Total)\")\n",
    "    if op_inc is None and gross is not None and op_exp is not None:\n",
    "        grouped_data[\"profit\"][\"Operating Income\"] = gross - op_exp\n",
    "\n",
    "    # Income Before Tax = Operating Income + (Interest Income - Interest Expense) + Other Income\n",
    "    inc_before_tax = grouped_data[\"profit\"].get(\"Income Before Tax\")\n",
    "    int_income = grouped_data[\"revenue\"].get(\"Interest Income\")\n",
    "    int_exp = grouped_data[\"expenses\"].get(\"Interest Expense\")\n",
    "    other_inc = grouped_data[\"revenue\"].get(\"Other Income\")\n",
    "    if inc_before_tax is None and op_inc is not None:\n",
    "        total_other = (int_income or 0) - (int_exp or 0) + (other_inc or 0)\n",
    "        grouped_data[\"profit\"][\"Income Before Tax\"] = op_inc + total_other\n",
    "\n",
    "    return grouped_data\n",
    "\n",
    "## Step 5a. Parse a given filing (the actual XBRL or XML)\n",
    "def parse_cashflow_from_10k(latest_10k_filing_XBRL_XML):\n",
    "    \"\"\"Extract cash flow data from a 10-K XBRL or XML filing\"\"\"\n",
    "    response = requests.get(latest_10k_filing_XBRL_XML, headers=HEADERS)\n",
    "\n",
    "    # Detect whether the document is XML or HTML\n",
    "    parser = \"xml\" if \"<?xml\" in response.text[:100] else \"html.parser\"\n",
    "    soup = BeautifulSoup(response.text, features=parser)\n",
    "\n",
    "    # Extract cashflow data using your earlier helper\n",
    "    output = parse_cashflow_from_xbrl(soup)\n",
    "\n",
    "    return output  # ‚úÖ actually return the data\n",
    "\n",
    "## Step 5b. Parse a given filing to get the income statement\n",
    "def parse_income_from_10k(latest_10k_filing_XBRL_XML):\n",
    "    \"\"\"Extract income statement data from a 10-K XBRL or XML filing\"\"\"\n",
    "    response = requests.get(latest_10k_filing_XBRL_XML, headers=HEADERS)\n",
    "\n",
    "    # Detect whether the document is XML or HTML\n",
    "    parser = \"xml\" if \"<?xml\" in response.text[:100] else \"html.parser\"\n",
    "    soup = BeautifulSoup(response.text, features=parser)\n",
    "\n",
    "    # Extract income data using your helper function\n",
    "    output = parse_income_from_xbrl(soup)\n",
    "\n",
    "    return output  # ‚úÖ return the parsed income statement data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43419f93-fbf4-424d-9294-842006a34357",
   "metadata": {},
   "source": [
    "#### [A2] Full flow of all supporting functions to return cashflow and income statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c20dca5d-e01d-49a6-8fc1-6bf0f68b11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consolidate all of the above into a flow:\n",
    "def get_financials_json(ticker):\n",
    "    \"\"\"End-to-end: from ticker ‚Üí CIK ‚Üí 10-K ‚Üí XBRL ‚Üí cashflow data\"\"\"\n",
    "    ## Step 1. Get CIK for the input ticker symbol\n",
    "    cik = get_cik(ticker)\n",
    "    if not cik:\n",
    "        raise ValueError(\"CIK not found.\")\n",
    "\n",
    "    ## Step 2. Get latest 10K url for the CIK (ticker)\n",
    "    filing_url, filing_date, report_date = get_latest_10k_url(cik)\n",
    "    if not filing_url:\n",
    "        raise ValueError(\"No 10-K filing found.\")\n",
    "\n",
    "    print(f\"Found 10-K filing: {filing_url} (filed {filing_date}, for {report_date})\")\n",
    "\n",
    "    # Step 3: Find actual XBRL XML file from 10K URL\n",
    "    xbrl_url = get_primary_xbrl_url(filing_url)\n",
    "    if not xbrl_url:\n",
    "        raise ValueError(\"No XBRL XML file found in filing.\")\n",
    "\n",
    "    print(f\"Using XBRL XML file: {xbrl_url}\")\n",
    "\n",
    "    # Step 5a: Parse cashflow data from that XML (4a embedded)\n",
    "    cashflow_data = parse_cashflow_from_10k(xbrl_url)\n",
    "    if not cashflow_data:\n",
    "        raise ValueError(\"Cash flow statement not found in filing.\")\n",
    "\n",
    "    # Step 5b: Parse income data from XML (4b embedded)\n",
    "    income_data = parse_income_from_10k(xbrl_url)\n",
    "    if not income_data:\n",
    "        raise ValueError(\"income statement not found in filing.\")\n",
    "\n",
    "    # Step 7: Return results\n",
    "    return {\n",
    "        \"ticker\": ticker,\n",
    "        \"cik\": cik,\n",
    "        \"source\": xbrl_url,\n",
    "        \"cashflow\": cashflow_data,\n",
    "        \"income_statement\": income_data,\n",
    "        \"filing_date\": filing_date,\n",
    "        \"report_date\": report_date,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6547c-4224-408e-a783-54f44b060f3b",
   "metadata": {},
   "source": [
    "### [A3] Store statements into firebase storage and the pointer to this in firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52d50d91-c08b-4aa9-8034-5e5efdabc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import firestore, storage\n",
    "\n",
    "# Load env vars (local dev only; safe to keep for API)\n",
    "load_dotenv()\n",
    "\n",
    "SERVICE_ACCOUNT_PATH = os.getenv(\"FIREBASE_SERVICE_ACCOUNT_JSON\")\n",
    "BUCKET_NAME = os.getenv(\"GCP_STORAGE_BUCKET\")\n",
    "\n",
    "if not BUCKET_NAME:\n",
    "    raise RuntimeError(\"Missing GCP_STORAGE_BUCKET in environment\")\n",
    "\n",
    "# --- Client initialization ---\n",
    "# Local dev: use service account JSON\n",
    "# Production (Cloud Run / Functions): use default credentials\n",
    "if SERVICE_ACCOUNT_PATH:\n",
    "    db = firestore.Client.from_service_account_json(SERVICE_ACCOUNT_PATH)\n",
    "    storage_client = storage.Client.from_service_account_json(SERVICE_ACCOUNT_PATH)\n",
    "else:\n",
    "    db = firestore.Client()\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "\n",
    "def upload_json_to_firebase_storage(\n",
    "    ticker: str,\n",
    "    year: int,\n",
    "    statement_type: str,   # \"incomeStatement\" | \"cashFlow\"\n",
    "    data: dict,\n",
    "):\n",
    "    \"\"\"\n",
    "    Uploads a financial statement dict as JSON to Firebase Storage.\n",
    "\n",
    "    Storage path:\n",
    "      gs://<bucket>/filings/{ticker}/{year}/statements/{statement_type}.json\n",
    "    \"\"\"\n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "    object_path = f\"filings/{ticker}/{year}/statements/{statement_type}.json\"\n",
    "    blob = bucket.blob(object_path)\n",
    "\n",
    "    blob.upload_from_string(\n",
    "        json.dumps(data, ensure_ascii=False),\n",
    "        content_type=\"application/json; charset=utf-8\",\n",
    "    )\n",
    "\n",
    "    gs_path = f\"gs://{BUCKET_NAME}/{object_path}\"\n",
    "    return gs_path, object_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0510567-dc26-4105-a7df-b5e7c25ca93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import firestore, storage\n",
    "import os\n",
    "\n",
    "def store_statements(\n",
    "    ticker: str,\n",
    "    year: int,\n",
    "    income_statement: dict = None,\n",
    "    cash_flow: dict = None,\n",
    "):\n",
    "    filing_doc_id = f\"{year}_10K\"\n",
    "\n",
    "    filing_ref = (\n",
    "        db.collection(\"companies\")\n",
    "          .document(ticker)\n",
    "          .collection(\"filings\")\n",
    "          .document(filing_doc_id)\n",
    "    )\n",
    "\n",
    "    # Ensure the filing doc exists\n",
    "    filing_ref.set({\n",
    "        \"ticker\": ticker,\n",
    "        \"year\": year,\n",
    "        \"type\": \"10-K\",\n",
    "        \"updatedAt\": firestore.SERVER_TIMESTAMP,\n",
    "    }, merge=True)\n",
    "\n",
    "    statements_col = filing_ref.collection(\"statements\")\n",
    "\n",
    "    # Income statement\n",
    "    if income_statement is not None:\n",
    "        gs_path, object_path = upload_json_to_firebase_storage(\n",
    "            ticker=ticker,\n",
    "            year=year,\n",
    "            statement_type=\"incomeStatement\",\n",
    "            data=income_statement,\n",
    "        )\n",
    "\n",
    "        statements_col.document(\"incomeStatement\").set({\n",
    "            \"statementType\": \"incomeStatement\",\n",
    "            \"storageGsPath\": gs_path,\n",
    "            \"storageObject\": object_path,\n",
    "            \"updatedAt\": firestore.SERVER_TIMESTAMP,\n",
    "        }, merge=True)\n",
    "\n",
    "    # Cash flow\n",
    "    if cash_flow is not None:\n",
    "        gs_path, object_path = upload_json_to_firebase_storage(\n",
    "            ticker=ticker,\n",
    "            year=year,\n",
    "            statement_type=\"cashFlow\",\n",
    "            data=cash_flow,\n",
    "        )\n",
    "\n",
    "        statements_col.document(\"cashFlow\").set({\n",
    "            \"statementType\": \"cashFlow\",\n",
    "            \"storageGsPath\": gs_path,\n",
    "            \"storageObject\": object_path,\n",
    "            \"updatedAt\": firestore.SERVER_TIMESTAMP,\n",
    "        }, merge=True)\n",
    "\n",
    "    print(f\"‚úÖ Stored statements for {ticker} {year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38688a43-1c2d-4d29-b49b-68e2d141f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10-K filing: https://www.sec.gov/Archives/edgar/data/1996862/000199686225000008/0001996862-25-000008-index.html (filed 2025-02-20, for 2024-12-31)\n",
      "Using XBRL XML file: https://www.sec.gov/Archives/edgar/data/1996862/000199686225000008/bg-20241231_htm.xml\n",
      "‚úÖ Stored statements for BG 2024\n"
     ]
    }
   ],
   "source": [
    "# This has been validated to work on 21st Jan 2026\n",
    "\n",
    "# Pull financial statements for ticker:\n",
    "financials = get_financials_json(\"BG\")\n",
    "\n",
    "# Store, for that ticker, into firestore and firebase storage, the statements pulled from the above 'financials'\n",
    "store_statements(\n",
    "    ticker=financials[\"ticker\"],\n",
    "    year=int(financials[\"report_date\"][:4]),\n",
    "    income_statement=financials[\"income_statement\"],\n",
    "    cash_flow=financials[\"cashflow\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a73baa-581c-4054-b0a0-33a81ffd3dc9",
   "metadata": {},
   "source": [
    "### [B] Get full 10K as Markdown Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a845c503-b706-42f5-98b6-47423a41ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Use your HTML finder (your existing function)\n",
    "def get_primary_html_url(index_url):\n",
    "    \"\"\"\n",
    "    Find the main 10-K HTML document inside the filing's index page.\n",
    "    Returns the actual HTML file URL (not the inline XBRL viewer).\n",
    "    \"\"\"\n",
    "    res = requests.get(index_url, headers=HEADERS)\n",
    "    if res.status_code != 200:\n",
    "        raise RuntimeError(f\"Failed to fetch index page: {res.status_code}\")\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        href = link[\"href\"].strip()\n",
    "        text = link.get_text(strip=True).lower()\n",
    "        href_lower = href.lower()\n",
    "\n",
    "        # Skip XMLs and exhibits\n",
    "        if any(x in href_lower for x in [\"_cal.xml\", \"_lab.xml\", \"_pre.xml\", \"_def.xml\", \".xml\"]):\n",
    "            continue\n",
    "        if \"exhibit\" in href_lower or \"ex\" in text:\n",
    "            continue\n",
    "\n",
    "        # Only consider HTML or Inline XBRL\n",
    "        if href_lower.endswith((\".htm\", \".html\")) or \"ix?doc=\" in href_lower:\n",
    "            score = 0\n",
    "            if \"10-k\" in href_lower or \"10k\" in href_lower:\n",
    "                score += 10\n",
    "            if \"ix?doc=\" in href_lower:\n",
    "                score += 20  # inline XBRL links usually indicate the primary document\n",
    "            if \"form\" in text or \"10-k\" in text:\n",
    "                score += 5\n",
    "            candidates.append((score, href))\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    # Pick the top-scoring link\n",
    "    best_href = sorted(candidates, key=lambda x: x[0], reverse=True)[0][1]\n",
    "\n",
    "    # Normalize the URL ‚Äî convert inline XBRL to raw HTML\n",
    "    if \"ix?doc=\" in best_href:\n",
    "        best_href = best_href.split(\"ix?doc=\")[-1]\n",
    "        if not best_href.startswith(\"https://\"):\n",
    "            best_href = \"https://www.sec.gov\" + best_href\n",
    "    elif not best_href.startswith(\"http\"):\n",
    "        if best_href.startswith(\"/\"):\n",
    "            best_href = \"https://www.sec.gov\" + best_href\n",
    "        else:\n",
    "            best_href = \"https://www.sec.gov/\" + best_href\n",
    "\n",
    "    return best_href\n",
    "\n",
    "## Convert HTML content to markdown text (also used in notebook: RAG-api)\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import re\n",
    "\n",
    "def clean_10k_html(html_content):\n",
    "    \"\"\"Convert messy 10-K HTML into clean text.\"\"\"\n",
    "    # Parse the HTML\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Remove hidden and metadata elements\n",
    "    for tag in soup([\"script\", \"style\", \"ix:header\", \"ix:hidden\", \"link\", \"meta\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Keep only the visible content\n",
    "    visible_html = str(soup)\n",
    "\n",
    "    # Convert to readable Markdown-style text\n",
    "    text_maker = html2text.HTML2Text()\n",
    "    text_maker.ignore_links = True\n",
    "    text_maker.ignore_images = True\n",
    "    text_maker.body_width = 0  # No line wrapping\n",
    "    clean_text = text_maker.handle(visible_html)\n",
    "\n",
    "    # Normalize spaces\n",
    "    clean_text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", clean_text)\n",
    "    return clean_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd0261-430c-4277-a30d-ca74965a26e9",
   "metadata": {},
   "source": [
    "### [B1] Store 10K into firebase storage and the pointer to this in firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbde3f7e-3782-4211-92df-af43aa3a28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run above functions and get output as text\n",
    "\n",
    "import requests\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "import requests\n",
    "import os\n",
    "# Make sure you actually load the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def store_10K_text_from_url(ticker, html_url, report_date):\n",
    "    \"\"\"\n",
    "    Fetch a 10-K HTML from a URL, convert it to cleaned text, and upload\n",
    "    the text to Firebase Storage under:\n",
    "    company_details/EDGAR (US)/filings/{ticker}_10K.txt\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1Ô∏è‚É£ Fetch the HTML content\n",
    "    headers = {\"User-Agent\": \"kurio-agent/1.0 (potatojacket9@gmail.com)\"}\n",
    "    res = requests.get(html_url, headers=headers)\n",
    "    if res.status_code != 200:\n",
    "        raise RuntimeError(f\"Failed to fetch HTML from SEC: {res.status_code}\")\n",
    "    html_content = res.text\n",
    "\n",
    "    # 2Ô∏è‚É£ Convert HTML to cleaned plain text\n",
    "    try:\n",
    "        text_data = clean_10k_html(html_content)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to clean HTML for {ticker}: {e}\")\n",
    "\n",
    "    # 3Ô∏è‚É£ Initialize Firebase Storage client #################################################\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    \n",
    "    from google.oauth2 import service_account\n",
    "    from google.cloud import firestore, storage\n",
    "    \n",
    "    \n",
    "    # -------------------------------\n",
    "    # Load .env\n",
    "    # -------------------------------\n",
    "    load_dotenv()\n",
    "    \n",
    "    SERVICE_ACCOUNT_PATH = os.getenv(\"FIREBASE_SERVICE_ACCOUNT_JSON\")\n",
    "    PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "    BUCKET_NAME = os.getenv(\"GCP_STORAGE_BUCKET\")\n",
    "    \n",
    "    if not SERVICE_ACCOUNT_PATH:\n",
    "        raise ValueError(\"Missing FIREBASE_SERVICE_ACCOUNT_JSON in .env\")\n",
    "    if not PROJECT_ID:\n",
    "        raise ValueError(\"Missing GCP_PROJECT_ID in .env\")\n",
    "    if not BUCKET_NAME:\n",
    "        raise ValueError(\"Missing GCP_STORAGE_BUCKET in .env\")\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Load Credentials (ONE source)\n",
    "    # -------------------------------\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_PATH\n",
    "    )\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Initialize Firestore + Storage \n",
    "    # -------------------------------\n",
    "    db = firestore.Client(credentials=creds, project=PROJECT_ID)\n",
    "    storage_client = storage.Client(credentials=creds, project=PROJECT_ID)\n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "    ##################################################################################################\n",
    "    \n",
    "    # 4Ô∏è‚É£ Path inside the bucket (TXT version)\n",
    "    year = int(report_date[:4])\n",
    "    object_path = f\"filings/{ticker}/{year}/10K.txt\"\n",
    "    blob = bucket.blob(object_path)\n",
    "    \n",
    "    # 5Ô∏è‚É£ Upload the cleaned text\n",
    "    blob.upload_from_string(text_data, content_type=\"text/plain; charset=utf-8\")\n",
    "\n",
    "    gs_path = f\"gs://{bucket}/{object_path}\"\n",
    "    \n",
    "    # Store only metadata + pointer in Firestore\n",
    "    filing_doc_id = f\"{year}_10K\"\n",
    "    db.collection(\"companies\") \\\n",
    "      .document(ticker) \\\n",
    "      .collection(\"filings\") \\\n",
    "      .document(filing_doc_id) \\\n",
    "      .set({\n",
    "          \"ticker\": ticker,\n",
    "          \"year\": year,\n",
    "          \"type\": \"10-K\",\n",
    "          \"storageGsPath\": gs_path,\n",
    "          \"storageBucket\": BUCKET_NAME,\n",
    "          \"storageObject\": object_path,\n",
    "          \"updatedAt\": firestore.SERVER_TIMESTAMP,\n",
    "      }, merge=True)\n",
    "\n",
    "    print(f\"‚úÖ Uploaded 10-K to Storage: {gs_path}\")\n",
    "    print(f\"‚úÖ Linked in Firestore: /companies/{ticker}/filings/{filing_doc_id}\")\n",
    "    \n",
    "    return blob.public_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be7a45-e7b9-4c11-ae46-ad0ac2c9dda5",
   "metadata": {},
   "source": [
    "#### Try running the 10K storage end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15254357-d897-4a72-8236-81bcd606a6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/1996862/000199686225000008/bg-20241231.htm\n",
      "‚úÖ Uploaded 10-K to Storage: gs://<Bucket: funwai-resume.firebasestorage.app>/filings/BG/2024/10K.txt\n",
      "‚úÖ Linked in Firestore: /companies/BG/filings/2024_10K\n"
     ]
    }
   ],
   "source": [
    "# This has been confirmed to work for an input ticker on 21st January 2026\n",
    "ticker = \"BG\"\n",
    "\n",
    "cik = get_cik(ticker)\n",
    "filing_url, filing_date, report_date = get_latest_10k_url(cik)\n",
    "\n",
    "html_url = get_primary_html_url(filing_url)\n",
    "print(html_url)\n",
    "\n",
    "isit = store_10K_text_from_url(ticker, html_url, report_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934afc6-5fe2-4812-b38b-c6940acdd046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
